j) 
import numpy as np

def power_iteration(A, num_simulations: int):
    # Choose a random vector to start with
    b_k = np.random.rand(A.shape[1])

    for _ in range(num_simulations):
        # Calculate the matrix-by-vector product Ab
        b_k1 = np.dot(A, b_k)
        
        # Re normalize the vector
        b_k1_norm = np.linalg.norm(b_k1)
        b_k = b_k1 / b_k1_norm

    eigenvalue = np.dot(b_k.T, np.dot(A, b_k)) / np.dot(b_k.T, b_k)
    eigenvector = b_k
    
    return eigenvalue, eigenvector

# Define the matrix
A = np.array([[4, 1, 1], 
              [1, 3, -1], 
              [1, -1, 2]])

eigenvalue, eigenvector = power_iteration(A, 1000)
print("Eigenvalue:", eigenvalue)
print("Eigenvector:", eigenvector)


ii) def qr_algorithm(A, num_simulations: int):
    Ak = A.copy()
    Q_prod = np.eye(A.shape[0])

    for _ in range(num_simulations):
        Q, R = np.linalg.qr(Ak)
        Ak = np.dot(R, Q)
        Q_prod = np.dot(Q_prod, Q)
    
    eigenvalues = np.diag(Ak)
    eigenvectors = Q_prod
    
    return eigenvalues, eigenvectors
j)
# Define the matrix
A = np.array([[4, 1, 1], 
              [1, 3, -1], 
              [1, -1, 2]])

eigenvalues, eigenvectors = qr_algorithm(A, 100)
print("Eigenvalues:", eigenvalues)
print("Eigenvectors:")
print(eigenvectors)

iii)
Comparison:
Power Iteration Technique:

Appropriate for determining the matching eigenvector and greatest eigenvalue.
efficient in terms of computation for big matrices.
If not altered, it might not find every eigenvalue or eigenvector.

QR Algorithm:
Able to locate each eigenvalue's matching eigenvector.
higher processing overhead than Power Iteration.
Ideal for smaller matrices or situations requiring all eigenvalues and eigenvectors.
